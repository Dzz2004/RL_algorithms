# **强化学习算法**
> **教师：Li ChangSheng**\
> **课程：Thu 11-13**\
> **学期：2024-2025第一学期** \
> **算法实现**
> - [x] 蒙特卡洛策略评估（MC）
> - [x] 动态规划方法(DP)
> - [x] Sarsa算法
> - [x] Q学习(Q-Learning)
> - [x] 策略梯度（PG）
> - [x] 近端策略优化（PPO）
> - [x] 深度Q网络（DQN）
> - [x] 演员-评论家（A2C）

## **项目介绍**
- 本项目是强化学习算法的实现，包括蒙特卡洛策略评估（MC）、动态规划方法(DP)、Sarsa算法、Q学习(Q-Learning)、策略梯度（PG）、近端策略优化（PPO）、深度Q网络（DQN）、演员-评论家（A2C）等算法的实现。
- 本项目的目的是为了帮助学生更好地理解强化学习算法的原理和实现方法，通过实现这些算法，学生可以更好的理解算法的原理和实现方法，提高学生的编程能力和理解能力。

## **项目结构**
- REPORT.md: 项目报告，其中包括项目的介绍、实现的算法、实验结果等内容。
- src/: 项目代码，其中包括蒙特卡洛策略评估（MC）、动态规划方法(DP)、Sarsa算法、Q学习(Q-Learning)、策略梯度（PG）、近端策略优化（PPO）、深度Q网络（DQN）、演员-评论家（A2C）等算法的实现。
- _results/: 各个算法的实验结果，保存在“算法名_results”目录下。包含训练过程、测试结果等内容。
- requirements.txt: 项目依赖的Python库。
- README.md: 项目说明文件。

## **使用说明**
1. 安装依赖库
```bash
pip install -r requirements.txt
```
2. 运行代码，进入src目录，运行.py文件，例如运行蒙特卡洛策略评估（MC）算法
```bash
cd src
python MC.py
```
3. 查看实验结果，实验结果保存在_results目录下，包含训练过程、测试结果等内容。
4. 查看项目报告，报告保存在REPORT.md文件中，其中包括项目的介绍、实现的算法、实验结果等内容。

## **参考内容**
部分代码非原创，参考了以下内容：
- [PPO算法实现代码来源](https://blog.csdn.net/NoahBBQ/article/details/135632332)
- [磨菇书](https://datawhalechina.github.io/easy-rl/#/)